{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Procesamiento Semántico de Palabras\n",
    "\n",
    "## 1.1 Propósito\n",
    "\n",
    "Se procesan una serie de textos y se obtiene el top k palabras más importantes y se exporta una lista para construir una nube de palabras a través de un programa externo.\n",
    "\n",
    "## 1.2 Metodología\n",
    "\n",
    "#### 1.2.1 Limpieza:\n",
    "- Convierte caracteres de utf8 a ascii y elimina errores.\n",
    "- Convierte mayúsculas en miinúsculas y quita acentos.\n",
    "- Elimina filas con entradas vacías.\n",
    "- Se deshace de palabras con un número de carácteres menor a 3.\n",
    "- Elimina stop [words](https://nlp.stanford.edu/IR-book/html/htmledition/dropping-common-terms-stop-words-1.html)\n",
    "\n",
    "#### 1.2.2 Vectorización TF-IDF\n",
    "\n",
    "- Genera un vectorizador de textos usando tf-idf.\n",
    "- Obtiene los vectores de importancia de palabra cada texto.\n",
    "\n",
    "\n",
    "Tf-idf significa *Term Frequency - Inverse Term Frequency*, tf-idf es utilizado en la recuperación de información y minería de texto. TF-idf es una medida estadística utilizada para evaluar la importancia de una palabra para un documento en una colección\n",
    "de textos o corpus.[2]\n",
    "\n",
    "En un corpus de texto grande, algunas palabras están muy presentes\n",
    "(por ejemplo, \"el\", \"a\", \"y\"), por lo tanto, llevarán muy poca información sobre el contenido real del\n",
    "documento. Si tuviéramos que alimentar los datos de conteo directamente a un\n",
    "clasificador, esos términos muy frecuentes tendrían mucho peso comparado\n",
    "con el peso de términos más raros pero más interesantes.[3]\n",
    "\n",
    "Usando la configuración predeterminada de [TfidfTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html?highlight=tf%20idf#sklearn.feature_extraction.text.TfidfTransformer) de la libreriía Sci-Kit:\n",
    "\n",
    "    TfidfTransformer(norm = 'l2', use_idf = True,\n",
    "                     smooth_idf = True, sublinear_tf = False)\n",
    "\n",
    "La frecuencia del término es decir, el número de veces que se produce un\n",
    "término en un documento determinado, se multiplica con el componente idf, que\n",
    "es calculado como:\n",
    "\n",
    "\n",
    ">![Pipeline_inicial_sin_detalle](./assets/eq.png)\n",
    "\n",
    "#### Ejemplo\n",
    "\n",
    "    Considere un documento que contiene 100 palabras en el que la palabra gato\n",
    "    aparece 3 veces. El término frecuencia (es decir, tf) para gato es\n",
    "    (3/100) = 0.03. Ahora, supongamos que tenemos 10 millones de documentos y\n",
    "    la palabra gato aparece en mil de estos. La frecuencia inversa del\n",
    "    documento (es decir, idf) se calcula como log(10,000,001 / 1,000+1) = 4.\n",
    "    Por lo tanto, el peso Tf-idf es el producto de estas cantidades:\n",
    "    0.03 * 4 = 0.12.\n",
    "\n",
    "\n",
    "A continuación se muestra la matríz TF-IDF de un conjunto de documentos de\n",
    "diferentes temas tales como \"air\", \"pollution\", etc. con un conjunto de palabras\n",
    "etiquetadas como d0, d1, dn:\n",
    "\n",
    ">![Pipeline_inicial_sin_detalle](./assets/word_document.png)\n",
    "   Matríz de words-documents, cada columna corresponde a un documento, cada fila a una palabra. Una celda almacena la frecuencia de una palabra en un documento, las celdas oscuras indican altas frecuencias de palabras. La clusterización por topic Modelling agrupan los\n",
    "   documentos, que usan palabras similares, así como las palabras que aparecen\n",
    "   en un conjunto similar de documentos. Los patrones resultantes se\n",
    "   denominan \"temas\" o \"tópicos\".\n",
    "\n",
    "  Obtenido de: [http://www.issac-conference.org/2015/Slides/Moitra.pdf](http://www.issac-conference.org/2015/Slides/Moitra.pdf)\n",
    "  \n",
    "Finalmente se  extraen las  top-25 palabras para generar la   nubede palabras y las top-20 para un  análisis externo.\n",
    "  #####  Dependencias\n",
    "\n",
    "Los siguientes módulos son necesarios para ejecutar el código:\n",
    "\n",
    "- joblib==0.14.0\n",
    "- nltk==3.4.5\n",
    "- numpy==1.17.4\n",
    "- pandas==0.25.3\n",
    "- python-dateutil==2.8.1\n",
    "- pytz==2019.3\n",
    "- scikit-learn==0.21.3\n",
    "- scipy==1.3.3\n",
    "- six==1.13.0\n",
    "- sklearn==0.0\n",
    "\n",
    "## 1.4 Resultados\n",
    "\n",
    "Se extrajo el contenido semántico de los conjuntos de palabras y se realizó la nube de palabras en https://www.wordclouds.com.\n",
    "\n",
    "Responsable: Daniel Bustillos (juan.bustillos@itdp.org)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Configuraciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#general\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "from joblib import dump, load\n",
    "sys.path.append(\"./scripts\") \n",
    "\n",
    "# limpieza y Steamming\n",
    "from cleaning_steamming import CleanTools\n",
    "\n",
    "# Análisis de importancia por TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Configuraciones\n",
    "\n",
    "Ninguna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Definición de parámetros\n",
    "definimos la columna a procesar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "columna = \"Limitación\"\n",
    "columns_not_duplicate = [\"id\"]\n",
    "columns_to_clean = columna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Importación de datos\n",
    "\n",
    "En esta sección cargue todos los datos que serán empleados en los análisis subsecuentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nombre de la empresa donde trabaja_nom</th>\n",
       "      <th>Género</th>\n",
       "      <th>Edad</th>\n",
       "      <th>Adelantar</th>\n",
       "      <th>Adelantar_horas</th>\n",
       "      <th>Retrasar</th>\n",
       "      <th>Adelantar_horas.1</th>\n",
       "      <th>Porqué</th>\n",
       "      <th>Porqué_norm</th>\n",
       "      <th>Limitación</th>\n",
       "      <th>Limitación_norm</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Grupo GWTC</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>21 a 25</td>\n",
       "      <td>No</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NINGUNA</td>\n",
       "      <td>Ninguna</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QUIMI-KAO</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>18 a 20</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no veo beneficio en lo personal</td>\n",
       "      <td>No beneficio/conveniencia/necesidad</td>\n",
       "      <td>el cambio de medio del transporte puesto que a...</td>\n",
       "      <td>Aumento costo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grupo GWTC</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>41 a 45</td>\n",
       "      <td>Sí</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Evitar aglomeraciones</td>\n",
       "      <td>Evitar congestionamiento/riesgo TP</td>\n",
       "      <td>ninguna</td>\n",
       "      <td>Ninguna</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Nombre de la empresa donde trabaja_nom     Género     Edad Adelantar  \\\n",
       "0                             Grupo GWTC  Masculino  21 a 25        No   \n",
       "1                              QUIMI-KAO  Masculino  18 a 20        No   \n",
       "2                             Grupo GWTC  Masculino  41 a 45        Sí   \n",
       "\n",
       "   Adelantar_horas Retrasar  Adelantar_horas.1  \\\n",
       "0              1.0       No                1.0   \n",
       "1              0.0       No                0.0   \n",
       "2              1.0       No                0.0   \n",
       "\n",
       "                             Porqué                          Porqué_norm  \\\n",
       "0                               NaN                                  NaN   \n",
       "1  no veo beneficio en lo personal   No beneficio/conveniencia/necesidad   \n",
       "2            Evitar aglomeraciones    Evitar congestionamiento/riesgo TP   \n",
       "\n",
       "                                          Limitación Limitación_norm  id  \n",
       "0                                            NINGUNA         Ninguna   0  \n",
       "1  el cambio de medio del transporte puesto que a...   Aumento costo   1  \n",
       "2                                            ninguna         Ninguna   2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encuesta = pd.read_csv(\"./data/Base_preguntas abiertas.csv\")\n",
    "df_encuesta[\"id\"] = df_encuesta.index.tolist()\n",
    "df_encuesta.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Procesamiento/Análisis/Modelos\n",
    "\n",
    "### 5.1 Limpieza:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos palabras en \"/\", util en campos normalizados \"Porqué_norm\" y \"Limitación_norm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encuesta[columna] = df_encuesta[columna].str.replace('/',' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos el archivo de limipieza y steamming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...text_cleaner\n",
      "...stop words\n"
     ]
    }
   ],
   "source": [
    "ct = CleanTools()\n",
    "df_proc = ct.text_cleaner(df_encuesta, columns_to_clean=columns_to_clean, columns_not_na=\"id\")\n",
    "field_clean = ct.stem_sentence_apply(limpiar=True,\n",
    "                       columns_not_duplicate=columns_not_duplicate,\n",
    "                       columns_to_clean=columns_to_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtramos respuestas vacías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_clean = [text for text in field_clean if text != \"\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exportamos para nube de palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cambio medio transporte puesto aumento cambio economico gente sale carretera ir pasear vacacionar puesto debo usar carretera chapala llegar lugar trabajo mucha gente usa salir viaje aun deberian causan aglomeraciones usando cubrevocas diario tomando distancia desinfectandoce cada rato limito tener contacto personas traigan cubre bocas guarden distancia transporte trafica entrar salir trabajo sumo todas obras viales complica movilidad parte visto limitacion desempenado mayor porcentaje home office minimo desplazamiento area trabajo voy casa trabajando ahora pandemia facil moverse ciudad afecta x chapaleros suficientes camiones pandemia recortaron camiones van llenos salian cada 15 min ahora cada 30 min van super llenos pesimo servicio transporte malo monopolio nadie hace mucha gente ahi fraccionamiento parece hacen favor autoricen ingresar rutas urge trafico hace regreso casa insoportable retorno bien establecido km 13 solo paso debajo carretera satura paso transporte tardado qu solo ruta ue viene salto carretera chapala ningunagracias apoyo empresaal prestar vehiculo agradecer apoyo cuidarme cuidar demas indicacion quedarnos casa trafico ahorita trabajo limitacion trasladarme lugar trabajo transporte publico lento hace congestion camion ningun problema co traslado limitacion horarios medidas preventivas accesos asido igual transporte proporciona empresa sigue rubros sanidad correctos dinero gastando abitual momento encontrado algun problema transporte publico descompostura carro mantenimiento mismo salir solo tener contacto personas exponerte usar trasporte empresa evitar contacto muchas personas traslado companero vehiculo particular caro salir trabajo descansaron impertencion deabetes medidas prevencion espacios unidad proteccion poder visitar familiares pasear familia preocuparse traer medidas proteccion nunguna dinero niguna usar automoviles propios gasto costos mantenimiento gasolina camiones llenos falta transporte aglomeramiento gente problemas vivo cerca dado caso utilizar vehiculo puedo utillizar motocicleta veir caminando niguna falta trasporte falta trasporte costo combustible mantenimiento auto transporte publicoya pasa frecuencia pocos transportes publicos movilidad sigue mismo trafico calles ahora cambiaron horario hace mes medio entro hora temprano desplazo mejor tener coche vehiculo propio limitacion limitacion medio transporte personal ahora transladado empezara hacerlo tendria problme auto compania traslado trafico mover lugares gente faltar horario trabajo hace unas semanas via libre ultimamente vuelto ver increme trafico trabajo casa distanciamiento personal seguridad usar vehiculo particular gasto economico vehiculo basicamente limitacion centra medidas deben tener evitar contagios gente autobus utilizar diario automovil propio genera gastos necesidad home office limitacion momento asisito empresa 1 2 veces semana dias restantes trabajo casa trafico producido tantas obras viales baches asfaltos danados etc empresa apoya pago transporte uber transporte publico tarde demasiado salir ruta transporte publico llegar trabajo casa economicamente gasolina aglomeracion personas disminucion unidades transporte publico trasladar hijos tambien mayor tiempo espera rutas consecuente retardos camiones menos transporte horarios corridas extensos pasan tan continuos trabajo casa aplica debido trabajando casa ruta transporte empresa publico aeropuerto hacia av adolf horn trasladar tlaquepaque tomar ruta hacia destino uso trasporte publico pesar pandemia ruta salto siempre va lleno incluso personas puertas hace paradas cabe gente gasto superior gasolina home office necesidad llegar tarde peticion salir casa debido posibilidad contagiarse covid congestion gente transporte publico calles casi transporte mucha gente mismos miedo infeccion solamente voy ocasionalmente aportar pregunta mayoria tiempo home office limitaciones mayor tiempo espera transporte planeacion adecuada horas pico consecuencia gente transporte evitando sana distancia pocos camiones ruta saturados llenos horarios espaciosos cada camion trafico transporte va lleno retrasa entrada trabajo realidad echo traslado mejor resguardados casas horarios transporte publico retrasados provoca llegar tarde centro trabajo salga hora casa toque aglomeracion esperando transporte publico reduccion transporte publico tener auto propio asistiendo disminuyeron camiones pasan tarde falta transporte publico camiones van llenos deberia haber rutas pongan limite usuarios tomo camion chapala cajititlan arvento suficientes camiones salen cada 30 min van llenos sanitizan traen gel antibacterial van super llenos camiones mucha gente trabajamos rumbo aeropuerto gdl van llenos cualquier hora limitaciones trasladarme centro trabajo solo asistido par veces actividades necesarias programadas costo transporte publico elevo servico dan parece robo veo ningun extra brindaba hace meses creo situacion gobierno deberia ayudar gente costo gasolina importancia general confinamiento afluencia vehicular menor obviamente tiempos traslado tambien menores pocos camiones afortunadamente limitaciones camiones van llenos gente respeta reglas proteccion seguridad auto propio persona vulnerable caso falta apoyo solventar gasolina tener trabajar horario normal alguna flexibilidad incrementos contagios numero contagios sigue aumento podido regresar forma segura oficina ir trabajo atiende home office limitacion mejoro transito confinamiento escalonamiento horarios usar facilidad transporte publico debido aglomeraciones ello incrementado gasto dicho rubro pues uso transporte publico reducir riesgo contagio implico aumento costo usar auto particular puesto transporte privado empresa poder utilizar tren ligero riesgo contagio debido trabajado casa inicio pandemia presentarme transporte publico escaso riesgoso acumulacion gente momento vivo cerca fabrica obras publicasmas lentas trafico cargado casa embarazo economica economia pues gasolinas costando embargo pandemia costo gasolina bajo empresa da aopoyo gasolina aun asi pagar servicio mantenimiento auto tenia contemplado servicio kilometraje tiempo problemas transporte lugar vivo actualmente trabajo horario laboro 8 17 hrs medio transporte tendria usar autobus uso auto existencia personal contagiado obras periferico lopez mateos carreteras malas condiciones periferico nuevo periferico aplica tener caminar casa lugar tomo transporte debido alrededor 25 minutos caminando ademas manana lugares demasiado solos peligrosos uso transporte publico evitar espacios muchas personas propenso contagio ocasiona elevar gastos uso automovil frecuenta verdad afectacion ah minima solo transporte publico pasa tan frecuentemente mismo debemos acudir tomar carros sitio alguna plataforma celular menos opciones traslado disponible evitar aglomeraciones cambios horario limitaciones traslado trabajando home office traslado cosas trabajo computadora documentacion cada vez regreso voy casa poder laborar ocasionalmente tomar transporte publico siempre toman medidas sanitarias resto personas momento trafico visto disminuido entiendo incremento trabajo casa horarios escalonados'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(field_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_nube = \" \".join(field_clean)\n",
    "file2write=open(\"./data/procesado/texto para nube por columna/palabras\" + columna + \".txt\",'w')\n",
    "file2write.write(texto_nube)\n",
    "file2write.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Vectorización TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos el vectorizador para conocer las top k palabras más importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "corpus_vector = vectorizer.fit_transform(field_clean)\n",
    "feature_array = np.array(vectorizer.get_feature_names())\n",
    "mean_words = corpus_vector.toarray().mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos un nuevo dataframe y con la información de las palabras y su peso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_words_weighted = pd.DataFrame(columns=[\"word\", \"weight_Avg\"], index=[i for i in range(len(mean_words))])\n",
    "df_words_weighted[\"word\"] = feature_array\n",
    "df_words_weighted[\"weight_Avg\"] = mean_words\n",
    "df_words_weighted = df_words_weighted.sort_values(\"weight_Avg\", ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>weight_Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>transporte</td>\n",
       "      <td>0.055675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trabajo</td>\n",
       "      <td>0.041405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>casa</td>\n",
       "      <td>0.035614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>publico</td>\n",
       "      <td>0.033782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>limitacion</td>\n",
       "      <td>0.032388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>trafico</td>\n",
       "      <td>0.028146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gente</td>\n",
       "      <td>0.023374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>momento</td>\n",
       "      <td>0.022338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>camiones</td>\n",
       "      <td>0.021913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>traslado</td>\n",
       "      <td>0.019800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word  weight_Avg\n",
       "0  transporte    0.055675\n",
       "1     trabajo    0.041405\n",
       "2        casa    0.035614\n",
       "3     publico    0.033782\n",
       "4  limitacion    0.032388\n",
       "5     trafico    0.028146\n",
       "6       gente    0.023374\n",
       "7     momento    0.022338\n",
       "8    camiones    0.021913\n",
       "9    traslado    0.019800"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_words_weighted.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_words_weighted = df_words_weighted.head(25)\n",
    "df_words_weighted.to_csv(\"./data/procesado/top25 por columna/topk_palabras_\" + columna + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Nube de palabras\n",
    "La nube de palabras se realizó en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Referencias\n",
    "\n",
    "[1] [https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html](https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html), visitado el 12/12/2019.\n",
    "\n",
    "\n",
    "[2] [http://www.tfidf.com](http://www.tfidf.com), visitado el 12/12/2019.\n",
    "\n",
    "[3] [https://scikit-learn.org/stable/modules/feature_extraction.html?highlight=tfid](https://scikit-learn.org/stable/modules/feature_extraction.html?highlight=tfidf), visitado el 12/12/2019.\n",
    "\n",
    "[4] [https://mlexplained.com/2017/12/28/a-practical-introduction-to-nmf-nonnegative-matrix-factorization/](https://mlexplained.com/2017/12/28/a-practical-introduction-to-nmf-nonnegative-matrix-factorization/) , visitado el 11/12/2019.\n",
    "\n",
    "[5] Blair, S.J., Bi, Y. & Mulvenna, M.D. Appl Intell (2019). https://doi.org/10.1007/s10489-019-01438-z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
